{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924027ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 1 classes.\n",
      "zucchini,courgette,\n",
      "redfox,Vulpesvulpes,\n",
      "fryingpan,frypan,skillet,\n",
      "anemonefish,\n"
     ]
    }
   ],
   "source": [
    "# Learn to use pre-trained models from keras: https://keras.io/api/applications/\n",
    "# First we check that we can use the pre-trained network from keras to do inference\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "# Use the following line to download the weights to C:\\Users\\<<username>>\\.keras\\models\n",
    "#model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# I shfited the weights to my own folder\n",
    "model = MobileNetV2(weights='D:/data/vision_imagenet/mobilenetv2_pre_trained.h5')\n",
    "\n",
    "img_path = 'D:/data/vision_imagenet/test_images/'\n",
    "\n",
    "def mobilenet_preprocess(img):\n",
    "    return convert_to_tensor(preprocess_input(img), dtype=tf.float32)\n",
    "    \n",
    "test_datagen = ImageDataGenerator(preprocessing_function = mobilenet_preprocess)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    img_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# Generating dictionary to return class \n",
    "imagenet_classes = {}\n",
    "with open(\"D:/data/vision_imagenet/imagenet1000_clsidx_to_labels.txt\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace(\" \", \"\")\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        line = line.replace(\"'\", \"\")\n",
    "        [key,val]=line.split(\":\")\n",
    "        imagenet_classes[int(key)] = val\n",
    "\n",
    "# Performing Inference\n",
    "img, _ = test_generator.next()\n",
    "preds = model(img)\n",
    "preds = np.argmax(preds,axis=1)\n",
    "\n",
    "# printing out the predicted classes\n",
    "# Interesting that the VGG (pytorch) classified the first image as cucumber\n",
    "# While MobileNet classified it as a zucchini\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    print(imagenet_classes[preds[i]])\n",
    "\n",
    "#getting the weights into numpy\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a806925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "Conv1\n",
      "bn_Conv1\n",
      "Conv1_relu\n",
      "expanded_conv_depthwise\n",
      "expanded_conv_depthwise_BN\n",
      "expanded_conv_depthwise_relu\n",
      "expanded_conv_project\n",
      "expanded_conv_project_BN\n",
      "block_1_expand\n",
      "block_1_expand_BN\n",
      "block_1_expand_relu\n",
      "block_1_pad\n",
      "block_1_depthwise\n",
      "block_1_depthwise_BN\n",
      "block_1_depthwise_relu\n",
      "block_1_project\n",
      "block_1_project_BN\n",
      "block_2_expand\n",
      "block_2_expand_BN\n",
      "block_2_expand_relu\n",
      "block_2_depthwise\n",
      "block_2_depthwise_BN\n",
      "block_2_depthwise_relu\n",
      "block_2_project\n",
      "block_2_project_BN\n",
      "block_2_add\n",
      "block_3_expand\n",
      "block_3_expand_BN\n",
      "block_3_expand_relu\n",
      "block_3_pad\n",
      "block_3_depthwise\n",
      "block_3_depthwise_BN\n",
      "block_3_depthwise_relu\n",
      "block_3_project\n",
      "block_3_project_BN\n",
      "block_4_expand\n",
      "block_4_expand_BN\n",
      "block_4_expand_relu\n",
      "block_4_depthwise\n",
      "block_4_depthwise_BN\n",
      "block_4_depthwise_relu\n",
      "block_4_project\n",
      "block_4_project_BN\n",
      "block_4_add\n",
      "block_5_expand\n",
      "block_5_expand_BN\n",
      "block_5_expand_relu\n",
      "block_5_depthwise\n",
      "block_5_depthwise_BN\n",
      "block_5_depthwise_relu\n",
      "block_5_project\n",
      "block_5_project_BN\n",
      "block_5_add\n",
      "block_6_expand\n",
      "block_6_expand_BN\n",
      "block_6_expand_relu\n",
      "block_6_pad\n",
      "block_6_depthwise\n",
      "block_6_depthwise_BN\n",
      "block_6_depthwise_relu\n",
      "block_6_project\n",
      "block_6_project_BN\n",
      "block_7_expand\n",
      "block_7_expand_BN\n",
      "block_7_expand_relu\n",
      "block_7_depthwise\n",
      "block_7_depthwise_BN\n",
      "block_7_depthwise_relu\n",
      "block_7_project\n",
      "block_7_project_BN\n",
      "block_7_add\n",
      "block_8_expand\n",
      "block_8_expand_BN\n",
      "block_8_expand_relu\n",
      "block_8_depthwise\n",
      "block_8_depthwise_BN\n",
      "block_8_depthwise_relu\n",
      "block_8_project\n",
      "block_8_project_BN\n",
      "block_8_add\n",
      "block_9_expand\n",
      "block_9_expand_BN\n",
      "block_9_expand_relu\n",
      "block_9_depthwise\n",
      "block_9_depthwise_BN\n",
      "block_9_depthwise_relu\n",
      "block_9_project\n",
      "block_9_project_BN\n",
      "block_9_add\n",
      "block_10_expand\n",
      "block_10_expand_BN\n",
      "block_10_expand_relu\n",
      "block_10_depthwise\n",
      "block_10_depthwise_BN\n",
      "block_10_depthwise_relu\n",
      "block_10_project\n",
      "block_10_project_BN\n",
      "block_11_expand\n",
      "block_11_expand_BN\n",
      "block_11_expand_relu\n",
      "block_11_depthwise\n",
      "block_11_depthwise_BN\n",
      "block_11_depthwise_relu\n",
      "block_11_project\n",
      "block_11_project_BN\n",
      "block_11_add\n",
      "block_12_expand\n",
      "block_12_expand_BN\n",
      "block_12_expand_relu\n",
      "block_12_depthwise\n",
      "block_12_depthwise_BN\n",
      "block_12_depthwise_relu\n",
      "block_12_project\n",
      "block_12_project_BN\n",
      "block_12_add\n",
      "block_13_expand\n",
      "block_13_expand_BN\n",
      "block_13_expand_relu\n",
      "block_13_pad\n",
      "block_13_depthwise\n",
      "block_13_depthwise_BN\n",
      "block_13_depthwise_relu\n",
      "block_13_project\n",
      "block_13_project_BN\n",
      "block_14_expand\n",
      "block_14_expand_BN\n",
      "block_14_expand_relu\n",
      "block_14_depthwise\n",
      "block_14_depthwise_BN\n",
      "block_14_depthwise_relu\n",
      "block_14_project\n",
      "block_14_project_BN\n",
      "block_14_add\n",
      "block_15_expand\n",
      "block_15_expand_BN\n",
      "block_15_expand_relu\n",
      "block_15_depthwise\n",
      "block_15_depthwise_BN\n",
      "block_15_depthwise_relu\n",
      "block_15_project\n",
      "block_15_project_BN\n",
      "block_15_add\n",
      "block_16_expand\n",
      "block_16_expand_BN\n",
      "block_16_expand_relu\n",
      "block_16_depthwise\n",
      "block_16_depthwise_BN\n",
      "block_16_depthwise_relu\n",
      "block_16_project\n",
      "block_16_project_BN\n",
      "Conv_1\n",
      "Conv_1_bn\n",
      "out_relu\n",
      "global_average_pooling2d\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "# Printing the name of the layers in the MobileNet V2 model\n",
    "for i in range(len(model.layers)):\n",
    "    print(model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfdf912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,008\n",
      "Trainable params: 15,792\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[[[  2.6107793   -2.4533556    3.372181   ...   8.797878\n",
      "      2.5942407    2.6625347 ]\n",
      "   [ -4.976843    -2.0296478   -2.7282426  ...   9.872526\n",
      "      0.35207462   1.3558737 ]\n",
      "   [ -5.29366      2.067833    -1.8916581  ...   9.849913\n",
      "      6.2063527   -3.378016  ]\n",
      "   ...\n",
      "   [ -9.858162    -3.8254917    1.5010047  ...   7.3308954\n",
      "      1.5307584    4.829833  ]\n",
      "   [ -5.198724    -3.7039857    0.7684722  ...   8.817445\n",
      "      3.2089548   -1.836383  ]\n",
      "   [ -2.963264    -2.9339426    3.2613432  ...   9.532651\n",
      "      5.0770473   -3.4632292 ]]\n",
      "\n",
      "  [[ -6.540026   -11.087917     0.19821475 ...   8.764004\n",
      "      5.6555166    4.456813  ]\n",
      "   [  4.245256   -10.906492    -6.4715557  ...   7.4768972\n",
      "     -2.3294592    3.3855872 ]\n",
      "   [  0.29911363  -5.530188    -6.3872433  ...   6.2351756\n",
      "     -4.592539     2.412316  ]\n",
      "   ...\n",
      "   [ -1.5173247   -3.897974    -0.17827463 ...   2.4600182\n",
      "      3.682367    -0.7116367 ]\n",
      "   [ -2.300966    -3.2118797   -1.81467    ...   3.9812455\n",
      "     -0.19064522  -2.2602048 ]\n",
      "   [ -0.11906409  -7.457638     2.607714   ...   2.7588847\n",
      "     -0.9451523   -3.4825482 ]]\n",
      "\n",
      "  [[  0.608449    -5.682162    -1.8499944  ...   7.179599\n",
      "      8.491676    -2.9163537 ]\n",
      "   [  1.68381     -6.6035      -8.471835   ...   4.8370714\n",
      "     -2.292172     0.6172609 ]\n",
      "   [ -0.49348313  -7.4820347   -2.180928   ...   0.5834851\n",
      "      1.3452713    2.8783731 ]\n",
      "   ...\n",
      "   [ -1.2697026   -0.63124317  -2.0151296  ...   4.7466097\n",
      "      0.5789467   -5.4675455 ]\n",
      "   [  1.0683      -0.29952258  -0.8913591  ...   6.906683\n",
      "     -0.4769035   -6.076249  ]\n",
      "   [  8.102491    -3.4538054    6.1389027  ...   7.1970606\n",
      "      4.9396095   -6.860796  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 13.92325      7.2515697    8.797249   ...   2.1272488\n",
      "     -9.046057    -0.02631533]\n",
      "   [ -0.36574936   5.344315    -5.264101   ...   3.0472293\n",
      "      8.430137     3.4044514 ]\n",
      "   [  4.3268156    6.129081    -9.247766   ...  -1.4224288\n",
      "     12.732007    -0.2336055 ]\n",
      "   ...\n",
      "   [  2.5515912   -6.9766126    5.453244   ...  -5.4811177\n",
      "     10.925733     1.0228455 ]\n",
      "   [  6.978289     0.35619926   0.2960682  ...  -5.274416\n",
      "    -17.785265     2.7587292 ]\n",
      "   [  2.5551317   -6.4710236    0.05809021 ...  -0.279423\n",
      "    -11.597872     4.6138186 ]]\n",
      "\n",
      "  [[ -5.1775103    0.7338222   10.402327   ...  -4.3977604\n",
      "     14.618799     5.6807127 ]\n",
      "   [ -8.386899   -12.873886     9.312541   ...   8.968992\n",
      "      8.336732     5.257434  ]\n",
      "   [ -2.2335074   -8.892179     9.099941   ...  -4.3755856\n",
      "      8.241243     3.5293915 ]\n",
      "   ...\n",
      "   [  5.032735     3.316277    -3.072307   ...  -4.961239\n",
      "     16.123915    -5.8705482 ]\n",
      "   [ -5.6278586    7.6117325   -1.7925186  ...  -6.999182\n",
      "     -7.386114    -1.238576  ]\n",
      "   [  9.653666    -2.6987245    2.8311095  ...  -1.681716\n",
      "     -1.7574046   -0.6380318 ]]\n",
      "\n",
      "  [[ -0.21914649   0.57079476  10.044718   ...   8.211725\n",
      "     12.721369    -3.8630664 ]\n",
      "   [ -2.4406874    0.55041134  -1.9994698  ...  -2.7827868\n",
      "     -7.9432254    0.11486995]\n",
      "   [  6.4465265   -3.3520913    2.2453475  ...  -0.7534239\n",
      "     -9.320966    -1.6802058 ]\n",
      "   ...\n",
      "   [  0.43793356  -1.239285    -2.02463    ...  -1.0138844\n",
      "      4.8368535   -0.59804785]\n",
      "   [  4.995899    -1.8440144    0.2569189  ...   3.753059\n",
      "      8.429629    -0.34188467]\n",
      "   [ -3.685766     0.18009605   7.1064997  ...   0.47279596\n",
      "      6.898674    -0.17659885]]]], shape=(1, 56, 56, 24), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Implementing MobileNet V2 to check if I understand the concepts\n",
    "#\n",
    "# We will:\n",
    "# 1) Implement the model structure of MobileNet V2 until the 2nd bottleneck layer within the paper\n",
    "# 2) Load the keras pre-trained weights into the model\n",
    "# 3) Check that the outputs from our custom implementation is the same as the outputs from the keras model\n",
    "# Reason why we stop at the 2nd bottleneck layer is because this is the first instance of a residual connection being made\n",
    "# the rest of the model is repeating whatever has been done so far\n",
    "#\n",
    "# Mobilenet V2 explanation: https://www.youtube.com/watch?v=eZzr780Qxfg&list=PLLCGSi_WZBNftPaTaX4k4AwLp4VreDAwV&index=10\n",
    "#\n",
    "# Print intermediate output to check against my model implementation\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "model_intermediate = Model(inputs=model.input, outputs=model.get_layer('block_2_add').output)\n",
    "img_path = \"D:/data/vision_imagenet/test_images/0/fox.jpg\"\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "img = tf.convert_to_tensor(img)\n",
    "\n",
    "intermediate_output = model_intermediate(img)\n",
    "\n",
    "print(model_intermediate.summary())\n",
    "print(intermediate_output)\n",
    "\n",
    "# The following lines were used to print a visualisation from the keras model for reference\n",
    "# Very helpful in understanding the model architecture\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "337d7ec3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 112, 112, 32  864         ['input_7[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 112, 112, 32  128        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 112, 112, 32  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depthwise  (None, 112, 112, 32  288        ['re_lu_24[0][0]']               \n",
      " Conv2D)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 112, 112, 32  128        ['depthwise_conv2d_12[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 112, 112, 32  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 112, 112, 16  512         ['re_lu_25[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 112, 112, 16  64         ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 112, 112, 96  1536        ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 112, 112, 96  384        ['conv2d_26[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 112, 112, 96  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depthwise  (None, 56, 56, 96)  864         ['re_lu_26[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 56, 56, 96)  384         ['depthwise_conv2d_13[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 56, 56, 96)   0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 56, 56, 24)   2304        ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 56, 56, 24)  96          ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 56, 56, 144)  3456        ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 56, 56, 144)  576        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 56, 56, 144)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depthwise  (None, 56, 56, 144)  1296       ['re_lu_28[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 56, 56, 144)  576        ['depthwise_conv2d_14[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 56, 56, 144)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 56, 56, 24)   3456        ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 56, 56, 24)  96          ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)     (None, 56, 56, 24)   0           ['batch_normalization_41[0][0]', \n",
      "                                                                  'batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,008\n",
      "Trainable params: 15,792\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n",
      "tf.Tensor(\n",
      "[[[[  2.6107793   -2.4533556    3.372181   ...   8.797878\n",
      "      2.5942407    2.6625347 ]\n",
      "   [ -4.976843    -2.0296478   -2.7282426  ...   9.872526\n",
      "      0.35207462   1.3558737 ]\n",
      "   [ -5.29366      2.067833    -1.8916581  ...   9.849913\n",
      "      6.2063527   -3.378016  ]\n",
      "   ...\n",
      "   [ -9.858162    -3.8254917    1.5010047  ...   7.3308954\n",
      "      1.5307584    4.829833  ]\n",
      "   [ -5.198724    -3.7039857    0.7684722  ...   8.817445\n",
      "      3.2089548   -1.836383  ]\n",
      "   [ -2.963264    -2.9339426    3.2613432  ...   9.532651\n",
      "      5.0770473   -3.4632292 ]]\n",
      "\n",
      "  [[ -6.540026   -11.087917     0.19821475 ...   8.764004\n",
      "      5.6555166    4.456813  ]\n",
      "   [  4.245256   -10.906492    -6.4715557  ...   7.4768972\n",
      "     -2.3294592    3.3855872 ]\n",
      "   [  0.29911363  -5.530188    -6.3872433  ...   6.2351756\n",
      "     -4.592539     2.412316  ]\n",
      "   ...\n",
      "   [ -1.5173247   -3.897974    -0.17827463 ...   2.4600182\n",
      "      3.682367    -0.7116367 ]\n",
      "   [ -2.300966    -3.2118797   -1.81467    ...   3.9812455\n",
      "     -0.19064522  -2.2602048 ]\n",
      "   [ -0.11906409  -7.457638     2.607714   ...   2.7588847\n",
      "     -0.9451523   -3.4825482 ]]\n",
      "\n",
      "  [[  0.608449    -5.682162    -1.8499944  ...   7.179599\n",
      "      8.491676    -2.9163537 ]\n",
      "   [  1.68381     -6.6035      -8.471835   ...   4.8370714\n",
      "     -2.292172     0.6172609 ]\n",
      "   [ -0.49348313  -7.4820347   -2.180928   ...   0.5834851\n",
      "      1.3452713    2.8783731 ]\n",
      "   ...\n",
      "   [ -1.2697026   -0.63124317  -2.0151296  ...   4.7466097\n",
      "      0.5789467   -5.4675455 ]\n",
      "   [  1.0683      -0.29952258  -0.8913591  ...   6.906683\n",
      "     -0.4769035   -6.076249  ]\n",
      "   [  8.102491    -3.4538054    6.1389027  ...   7.1970606\n",
      "      4.9396095   -6.860796  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 13.92325      7.2515697    8.797249   ...   2.1272488\n",
      "     -9.046057    -0.02631533]\n",
      "   [ -0.36574936   5.344315    -5.264101   ...   3.0472293\n",
      "      8.430137     3.4044514 ]\n",
      "   [  4.3268156    6.129081    -9.247766   ...  -1.4224288\n",
      "     12.732007    -0.2336055 ]\n",
      "   ...\n",
      "   [  2.5515912   -6.9766126    5.453244   ...  -5.4811177\n",
      "     10.925733     1.0228455 ]\n",
      "   [  6.978289     0.35619926   0.2960682  ...  -5.274416\n",
      "    -17.785265     2.7587292 ]\n",
      "   [  2.5551317   -6.4710236    0.05809021 ...  -0.279423\n",
      "    -11.597872     4.6138186 ]]\n",
      "\n",
      "  [[ -5.1775103    0.7338222   10.402327   ...  -4.3977604\n",
      "     14.618799     5.6807127 ]\n",
      "   [ -8.386899   -12.873886     9.312541   ...   8.968992\n",
      "      8.336732     5.257434  ]\n",
      "   [ -2.2335074   -8.892179     9.099941   ...  -4.3755856\n",
      "      8.241243     3.5293915 ]\n",
      "   ...\n",
      "   [  5.032735     3.316277    -3.072307   ...  -4.961239\n",
      "     16.123915    -5.8705482 ]\n",
      "   [ -5.6278586    7.6117325   -1.7925186  ...  -6.999182\n",
      "     -7.386114    -1.238576  ]\n",
      "   [  9.653666    -2.6987245    2.8311095  ...  -1.681716\n",
      "     -1.7574046   -0.6380318 ]]\n",
      "\n",
      "  [[ -0.21914649   0.57079476  10.044718   ...   8.211725\n",
      "     12.721369    -3.8630664 ]\n",
      "   [ -2.4406874    0.55041134  -1.9994698  ...  -2.7827868\n",
      "     -7.9432254    0.11486995]\n",
      "   [  6.4465265   -3.3520913    2.2453475  ...  -0.7534239\n",
      "     -9.320966    -1.6802058 ]\n",
      "   ...\n",
      "   [  0.43793356  -1.239285    -2.02463    ...  -1.0138844\n",
      "      4.8368535   -0.59804785]\n",
      "   [  4.995899    -1.8440144    0.2569189  ...   3.753059\n",
      "      8.429629    -0.34188467]\n",
      "   [ -3.685766     0.18009605   7.1064997  ...   0.47279596\n",
      "      6.898674    -0.17659885]]]], shape=(1, 56, 56, 24), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Our custom implementation of the MobileNet V2 architecture\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.math import add\n",
    "\n",
    "# This series of layers is called \"Conv1\" in the keras implementation\n",
    "# It is the conv2d layer in the paper. output channels = 32\n",
    "# Model is using ReLU 6, which has a max_value of 6, more efficient when using low precision computations\n",
    "\n",
    "output_channels = 32\n",
    "stride = 2\n",
    "\n",
    "x_input = layers.Input((224, 224, 3))\n",
    "x = layers.Conv2D(output_channels, (3, 3), strides=(stride, stride), padding='same', use_bias=False)(x_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "# This series of layers is called \"expanded\" in the keras implementation\n",
    "# It is the first bottleneck layer in the paper. output channels = 16\n",
    "# This features the depthwise conv2d which does 3x3 conv and outputs 1 channel per layer\n",
    "# The 1x1 conv (cheaper than 3x3) is to get a combination across all the channels\n",
    "# bias are all not required because we are using batch norm right after\n",
    "\n",
    "output_channels = 16\n",
    "\n",
    "x = layers.DepthwiseConv2D(kernel_size=(3,3),padding='same',use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = layers.Conv2D(output_channels, (1, 1), use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "# This next series of layers is called \"block_1\" in the keras implementation\n",
    "# It is the second bottleneck layer in the paper. \n",
    "# Expansion factor, t = 6. output channels = 24. Stride =2.\n",
    "# Expansion layers are 1x1 regular conv2d\n",
    "\n",
    "input_channels = 16\n",
    "output_channels = 24\n",
    "expansion_factor = 6\n",
    "stride = 2\n",
    "\n",
    "x = layers.Conv2D(input_channels*expansion_factor, (1, 1), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = layers.DepthwiseConv2D(kernel_size=(3,3),strides=(stride, stride),padding='same',use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = layers.Conv2D(output_channels, (1, 1), use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "# This next series of layers is called \"block_2\" in the keras implementation\n",
    "# This is the repeat (n=2) in the second bottleneck layer in the paper\n",
    "# First residual connection. We use a new variable y to store all the intermediate calculations\n",
    "# Expansion factor, t=6. output channnels = 24. Stride = 1.\n",
    "\n",
    "input_channels = 24\n",
    "output_channels = 24\n",
    "expansion_factor = 6\n",
    "stride = 1\n",
    "\n",
    "y = layers.Conv2D(input_channels*expansion_factor, (1, 1), padding='same', use_bias=False)(x)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = keras.layers.ReLU(max_value=6)(y)\n",
    "\n",
    "y = layers.DepthwiseConv2D(kernel_size=(3,3),strides=(stride, stride),padding='same',use_bias=False)(y)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = keras.layers.ReLU(max_value=6)(y)\n",
    "\n",
    "y = layers.Conv2D(output_channels, (1, 1), use_bias=False)(y)\n",
    "y = layers.BatchNormalization()(y)\n",
    "\n",
    "x = add(x, y) \n",
    "\n",
    "# Compiling the model\n",
    "model_custom = models.Model(inputs = x_input, outputs = x)\n",
    "\n",
    "model_custom.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model_custom.summary()\n",
    "\n",
    "#setting weight from pre-trained model into custom model\n",
    "\n",
    "#Layer 0 is the input layer\n",
    "\n",
    "#keras model: conv1\n",
    "\n",
    "model_custom.layers[1].weights[0].assign(weights[0])\n",
    "\n",
    "#batch norm layer as 4 x 32 weights\n",
    "model_custom.layers[2].weights[0].assign(weights[1])\n",
    "model_custom.layers[2].weights[1].assign(weights[2])\n",
    "model_custom.layers[2].weights[2].assign(weights[3])\n",
    "model_custom.layers[2].weights[3].assign(weights[4])\n",
    "\n",
    "#layer 3 is relu with no weights\n",
    "\n",
    "#keras model: expanded\n",
    "\n",
    "model_custom.layers[4].weights[0].assign(weights[5])\n",
    "\n",
    "model_custom.layers[5].weights[0].assign(weights[6])\n",
    "model_custom.layers[5].weights[1].assign(weights[7])\n",
    "model_custom.layers[5].weights[2].assign(weights[8])\n",
    "model_custom.layers[5].weights[3].assign(weights[9])\n",
    "\n",
    "#layer 6 is relu with no weights\n",
    "\n",
    "model_custom.layers[7].weights[0].assign(weights[10])\n",
    "\n",
    "model_custom.layers[8].weights[0].assign(weights[11])\n",
    "model_custom.layers[8].weights[1].assign(weights[12])\n",
    "model_custom.layers[8].weights[2].assign(weights[13])\n",
    "model_custom.layers[8].weights[3].assign(weights[14])\n",
    "\n",
    "#keras model: block1\n",
    "\n",
    "model_custom.layers[9].weights[0].assign(weights[15])\n",
    "\n",
    "model_custom.layers[10].weights[0].assign(weights[16])\n",
    "model_custom.layers[10].weights[1].assign(weights[17])\n",
    "model_custom.layers[10].weights[2].assign(weights[18])\n",
    "model_custom.layers[10].weights[3].assign(weights[19])\n",
    "\n",
    "#layer 11 is relu with no weights\n",
    "\n",
    "model_custom.layers[12].weights[0].assign(weights[20])\n",
    "\n",
    "model_custom.layers[13].weights[0].assign(weights[21])\n",
    "model_custom.layers[13].weights[1].assign(weights[22])\n",
    "model_custom.layers[13].weights[2].assign(weights[23])\n",
    "model_custom.layers[13].weights[3].assign(weights[24])\n",
    "\n",
    "#layer 14 is relu with no weights\n",
    "\n",
    "model_custom.layers[15].weights[0].assign(weights[25])\n",
    "\n",
    "model_custom.layers[16].weights[0].assign(weights[26])\n",
    "model_custom.layers[16].weights[1].assign(weights[27])\n",
    "model_custom.layers[16].weights[2].assign(weights[28])\n",
    "model_custom.layers[16].weights[3].assign(weights[29])\n",
    "\n",
    "#Block2\n",
    "model_custom.layers[17].weights[0].assign(weights[30])\n",
    "\n",
    "model_custom.layers[18].weights[0].assign(weights[31])\n",
    "model_custom.layers[18].weights[1].assign(weights[32])\n",
    "model_custom.layers[18].weights[2].assign(weights[33])\n",
    "model_custom.layers[18].weights[3].assign(weights[34])\n",
    "\n",
    "#layer 19 is relu with no weights\n",
    "\n",
    "model_custom.layers[20].weights[0].assign(weights[35])\n",
    "\n",
    "model_custom.layers[21].weights[0].assign(weights[36])\n",
    "model_custom.layers[21].weights[1].assign(weights[37])\n",
    "model_custom.layers[21].weights[2].assign(weights[38])\n",
    "model_custom.layers[21].weights[3].assign(weights[39])\n",
    "\n",
    "#layer 22 is relu with no weights\n",
    "\n",
    "model_custom.layers[23].weights[0].assign(weights[40])\n",
    "\n",
    "model_custom.layers[24].weights[0].assign(weights[41])\n",
    "model_custom.layers[24].weights[1].assign(weights[42])\n",
    "model_custom.layers[24].weights[2].assign(weights[43])\n",
    "model_custom.layers[24].weights[3].assign(weights[44])\n",
    "\n",
    "#layer 25 is add with no weights\n",
    "\n",
    "intermediate_output = model_custom(img)\n",
    "print(intermediate_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
